
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../imported_data/salary_data2.csv does not exist: '../imported_data/salary_data2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f9abbab70153>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import csv to df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msalary_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../imported_data/salary_data2.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msalary_df2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ../imported_data/salary_data2.csv does not exist: '../imported_data/salary_data2.csv'"
     ]
    }
   ],
   "source": [
    "# import csv to df\n",
    "salary_df2 = pd.read_csv(\"../imported_data/salary_data2.csv\")\n",
    "salary_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns to keep \n",
    "salary_df2 = salary_df2[[\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q10\",\"Q13_Part_1\",\"Q13_Part_2\",\"Q13_Part_3\",\"Q13_Part_4\",\"Q13_Part_5\",\"Q13_Part_6\",\"Q13_Part_7\",\"Q13_Part_8\",\"Q13_Part_9\",\"Q13_Part_10\",\"Q13_Part_11\",\"Q13_Part_12\",\"Q14\",\"Q15\",\"Q16_Part_1\",\"Q16_Part_2\",\"Q16_Part_3\",\"Q16_Part_4\",\"Q16_Part_5\",\"Q16_Part_6\",\"Q16_Part_7\",\"Q16_Part_8\",\"Q16_Part_9\",\"Q16_Part_10\",\"Q16_Part_11\",\"Q16_Part_12\",\"Q18_Part_1\",\"Q18_Part_2\",\"Q18_Part_3\",\"Q18_Part_4\",\"Q18_Part_5\",\"Q18_Part_6\",\"Q18_Part_7\",\"Q18_Part_8\",\"Q18_Part_9\",\"Q18_Part_10\",\"Q18_Part_11\",\"Q18_Part_12\",\"Q19\",\"Q20_Part_1\",\"Q20_Part_2\",\"Q20_Part_3\",\"Q20_Part_4\",\"Q20_Part_5\",\"Q20_Part_6\",\"Q20_Part_7\",\"Q20_Part_8\",\"Q20_Part_9\",\"Q20_Part_10\",\"Q20_Part_11\",\"Q20_Part_12\",\"Q23\",\"Q24_Part_1\",\"Q24_Part_2\",\"Q24_Part_3\",\"Q24_Part_4\",\"Q24_Part_5\",\"Q24_Part_6\",\"Q24_Part_7\",\"Q24_Part_8\",\"Q24_Part_9\",\"Q24_Part_10\",\"Q24_Part_11\",\"Q24_Part_12\",\"Q28_Part_1\",\"Q28_Part_2\",\"Q28_Part_3\",\"Q28_Part_4\",\"Q28_Part_5\",\"Q28_Part_6\",\"Q28_Part_7\",\"Q28_Part_8\",\"Q28_Part_9\",\"Q28_Part_10\",\"Q28_Part_11\",\"Q28_Part_12\",\"Q29_Part_1\",\"Q29_Part_2\",\"Q29_Part_3\",\"Q29_Part_4\",\"Q29_Part_5\",\"Q29_Part_6\",\"Q29_Part_7\",\"Q29_Part_8\",\"Q29_Part_9\",\"Q29_Part_10\",\"Q29_Part_11\",\"Q29_Part_12\",\"Q34_Part_1\",\"Q34_Part_2\",\"Q34_Part_3\",\"Q34_Part_4\",\"Q34_Part_5\",\"Q34_Part_6\",\"Q34_Part_7\",\"Q34_Part_8\",\"Q34_Part_9\",\"Q34_Part_10\",\"Q34_Part_11\",\"Q34_Part_12\"]]\n",
    "salary_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first row that included the extra question column\n",
    "salary_df2 = salary_df2.drop(salary_df2.index[0])\n",
    "salary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renamed the columns to a more informative title \n",
    "salary_df2= salary_df2.set_axis([\"age\",\"gender\",\"country\",\"education\",\"title\",\"size\",\"data_prof_size\",\"mach_learn_presence\",\"salary\",\n",
    "                                 \"udacity\",\"coursera\",\"edx\",\"datacamp\",\"dataquest\",\"kaggle\",\"fastai\",\"udemy\",\"linkedin\",\"university\",\"plat_none\",\"plat_other\",\n",
    "                                 \"prime_tool\",\n",
    "                                 \"length_coding\",\n",
    "                                 \"jupyter\",\"rstudio\",\"pycharm\",\"atom\",\"matlab\",\"vsc\",\"spyder\",\"vim_emacs\",\"notepad++\",\"sublime\",\"env_none\",\"env_other\",\n",
    "                                 \"python\",\"r\",\"sql\",\"c\",\"c++\",\"java\",\"javascript\",\"typescript\",\"bash\",\"lan_matlab\",\"lan_none\",\"lan_other\",\n",
    "                                 \"first_program\",\n",
    "                                 \"ggplot\",\"matplotlib\",\"altair\",\"shiny\",\"d3\",\"plotly\",\"bokeh\",\"seaborn\",\"geoplotlib\",\"leaflet\",\"vis_none\",\"vis_other\",\n",
    "                                 \"years_mach_learn\",\"regression\",\"tree_forest\",\"gradient_boost\",\"bayesian\",\"evolutionary\",\"dnn\",\"cnn\",\"gan\",\"rnn\",\"bert\",\"mach_none\",\"mach_other\",\n",
    "                                 \"scikit\",\"tensor_flow\",\"keras\",\"random_forest\",\"xgboost\",\"pytorch\",\"caret\",\"lightgbm\",\"sparkmlib\",\"fastai_2\",\"frame_none\",\"frame_other\",\n",
    "                                 \"gcp\",\"aws\",\"azure\",\"ibm_cloud\",\"alibaba_cloud\",\"salesforce_cloud\",\"oracle_cloud\",\"sap_cloud\",\"vmware_cloud\",\"redhat_cloud\",\"cloud_none\",\"cloud_other\",\n",
    "                                 \"mysql\",\"postgres\",\"sql_lite\",\"sqlserver\",\"oracle\",\"micro_acess\",\"aws_data\",\"aws_dynamo\",\"azure_sql\",\"google_sql\",\"database_none\",\"database_other\"], \n",
    "                                axis='columns', inplace=False)\n",
    "salary_df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacted the nans with 0 values \n",
    "salary_df2 = salary_df2.replace(np.nan, 0)\n",
    "salary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief check that the value counts match the columns \n",
    "salary_df2[\"udacity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing value names from strings to 1 \n",
    "\n",
    "replace_columns = (\"udacity\",\"coursera\",\"edx\",\"datacamp\",\"dataquest\",\"kaggle\",\"fastai\",\"udemy\",\"linkedin\",\"university\",\"plat_none\",\"plat_other\",\n",
    "                                 \"jupyter\",\"rstudio\",\"pycharm\",\"atom\",\"matlab\",\"vsc\",\"spyder\",\"vim_emacs\",\"notepad++\",\"sublime\",\"env_none\",\"env_other\",\n",
    "                                 \"python\",\"r\",\"sql\",\"c\",\"c++\",\"java\",\"javascript\",\"typescript\",\"bash\",\"lan_matlab\",\"lan_none\",\"lan_other\",\n",
    "                                 \"ggplot\",\"matplotlib\",\"altair\",\"shiny\",\"d3\",\"plotly\",\"bokeh\",\"seaborn\",\"geoplotlib\",\"leaflet\",\"vis_none\",\"vis_other\",\n",
    "                                 \"years_mach_learn\",\"regression\",\"tree_forest\",\"gradient_boost\",\"bayesian\",\"evolutionary\",\"dnn\",\"cnn\",\"gan\",\"rnn\",\"bert\",\"mach_none\",\"mach_other\",\n",
    "                                 \"scikit\",\"tensor_flow\",\"keras\",\"random_forest\",\"xgboost\",\"pytorch\",\"caret\",\"lightgbm\",\"sparkmlib\",\"fastai_2\",\"frame_none\",\"frame_other\",\n",
    "                                 \"gcp\",\"aws\",\"azure\",\"ibm_cloud\",\"alibaba_cloud\",\"salesforce_cloud\",\"oracle_cloud\",\"sap_cloud\",\"vmware_cloud\",\"redhat_cloud\",\"cloud_none\",\"cloud_other\",\n",
    "                                 \"mysql\",\"postgres\",\"sql_lite\",\"sqlserver\",\"oracle\",\"micro_acess\",\"aws_data\",\"aws_dynamo\",\"azure_sql\",\"google_sql\",\"database_none\",\"database_other\")\n",
    "\n",
    "\n",
    "\n",
    "for column in replace_columns:\n",
    "    boolean_condition = salary_df2[column] != 0\n",
    "    new_value = 1\n",
    "    salary_df2.loc[boolean_condition, column] = new_value\n",
    "\n",
    "salary_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if strings converted to 1 \n",
    "salary_df2[\"udacity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the age column from ranges to two seprate values\n",
    "age = salary_df2['age'].str.split('-', 1, expand=True)\n",
    "age[0] = age[0].str.replace('+', ' ')\n",
    "age.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting the objects to numerics \n",
    "age[0] = pd.to_numeric(age[0])\n",
    "age[1] = pd.to_numeric(age[1])\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the average of the ages \n",
    "avg_age = (age[0]+age[1])/2\n",
    "avg_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the age column to average age \n",
    "salary_df2['age'] = avg_age\n",
    "salary_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the salary from a range into two columns \n",
    "salary = salary_df2['salary'].str.split('-', 1, expand=True)\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of extra characters from the salary column \n",
    "salary[0] = salary[0].str.replace('$', '')\n",
    "salary[0] = salary[0].str.replace(',', '')\n",
    "salary[0] = salary[0].str.replace('>', '')\n",
    "\n",
    "salary[1] = salary[1].str.replace(',', '')\n",
    "salary[1] = salary[1].str.replace('>', '')\n",
    "\n",
    "\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing salary nans to 0 values \n",
    "salary = salary.replace(np.nan, 0)\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the objects to ints in the salary column\n",
    "salary[0] = pd.to_numeric(salary[0])\n",
    "salary[1] = pd.to_numeric(salary[1])\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the average salary from the range\n",
    "avg_salary = (salary[0]+salary[1])/2\n",
    "avg_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the originak salary column for an average salary \n",
    "salary_df2['salary'] = avg_salary\n",
    "salary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter where salary is >0 \n",
    "salary_df2 = salary_df2.loc[salary_df2['salary'] > 0]\n",
    "salary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminating any remaining columns with student values\n",
    "salary_df2 = salary_df2.loc[salary_df2['title'] != 'Student']\n",
    "salary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df2['size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a company size classification\n",
    "salary_df2.loc[salary_df2['size'] == '0-49 employees', 'size']  = 'small'\n",
    "salary_df2.loc[salary_df2['size'] == '50-249 employees', 'size'] = 'small'\n",
    "salary_df2.loc[salary_df2['size'] == '250-999 employees', 'size'] = 'small'\n",
    "salary_df2.loc[salary_df2['size'] == '1000-9,999 employees', 'size'] = 'medium'\n",
    "salary_df2.loc[salary_df2['size'] == '> 10,000 employees', 'size'] = 'large'\n",
    "salary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df2.reset_index(drop=True, inplace=True)\n",
    "salary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make id row - very last step, then reset index\n",
    "salary_df2.to_csv(\"../exported_data/salary_data2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############Sandy###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv to df\n",
    "salary_df1 = pd.read_csv(\"../imported_data/salary_data1.csv\", header=3)\n",
    "salary_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the columns we need\n",
    "salary_df1 = salary_df1[[\"Survey Year\", \"SalaryUSD\", \"Country\", \"PrimaryDatabase\", \"YearsWithThisDatabase\", \"EmploymentStatus\", \"JobTitle\", \"ManageStaff\", \"YearsWithThisTypeOfJob\", \"OtherPeopleOnYourTeam\", \"DatabaseServers\", \"Education\", \"EducationIsComputerRelated\", \"Certifications\", \"HoursWorkedPerWeek\", \"TelecommuteDaysPerWeek\", \"EmploymentSector\"]]\n",
    "salary_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the datatypes to see what needs to be changed\n",
    "salary_df1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out non-integer characters in the salary column\n",
    "salary_df1[\"SalaryUSD\"] = salary_df1[\"SalaryUSD\"].str.replace(\",\", \"\")\n",
    "salary_df1[\"SalaryUSD\"] = salary_df1[\"SalaryUSD\"].str.replace(\" \", \"\")\n",
    "salary_df1[\"SalaryUSD\"] = salary_df1[\"SalaryUSD\"].str.replace(\"$\", \"\")\n",
    "# change the salary type to float\n",
    "salary_df1[\"SalaryUSD\"] = salary_df1[\"SalaryUSD\"].astype(float)\n",
    "# check to make sure the salary column is correct data type\n",
    "salary_df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take salaries that are greater than 1000 to get rid of low outliers\n",
    "salary_df1 = salary_df1.loc[salary_df1[\"SalaryUSD\"] > 1000]\n",
    "salary_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out incorrect/nonsensical data from \"YearsWithThisDatabase\"\n",
    "salary_df1 = salary_df1.loc[(salary_df1[\"YearsWithThisDatabase\"] < 2050)]\n",
    "salary_df1 = salary_df1.loc[(salary_df1[\"YearsWithThisDatabase\"] != 1050)]\n",
    "salary_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some people entered the year they started instead of amount of years worked in the column \"YearsWithThisDatabase\"\n",
    "# this loop takes the year they started and subtracts it from the year they took the survey to get the total yeras worked there\n",
    "for index, row in salary_df1.iterrows():\n",
    "    if row[4] > 1000:\n",
    "        number = row[0] - row[4]\n",
    "        # print out the number to make sure it worked\n",
    "        print(number)\n",
    "        salary_df1.at[index, \"YearsWithThisDatabase\"] = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in descending order to make sure numbers in the 2000s don't appear in the \"YearsWithThisDatabase\" column\n",
    "salary_df1.sort_values(\"YearsWithThisDatabase\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only needed the \"survey year\" column to complete the previous step, so we are removing it now\n",
    "del salary_df1[\"Survey Year\"]\n",
    "salary_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the country to regions csv\n",
    "country_to_region_df = pd.read_csv(\"../imported_data/country_to_region.csv\")\n",
    "country_to_region_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge salary df with county to region df so each row specifies the region as well as country\n",
    "merged_df = pd.merge(salary_df1, country_to_region_df, on=\"Country\", how=\"outer\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleted the last row because it was all NaN's\n",
    "merged_df = merged_df[:-1]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all column headers to be lowercase to fit postgres format\n",
    "merged_df.columns = map(str.lower, merged_df.columns)\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a column called id to be used as the primary key\n",
    "merged_df = merged_df.reset_index()\n",
    "merged_df = merged_df.rename(columns={\"index\":\"id\"})\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of columns to make postgresql schema\n",
    "merged_df.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data types of columns to make postgresql schema\n",
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned df to a csv\n",
    "merged_df.to_csv(\"../exported_data/salary_data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure settings for RDS\n",
    "from config import sandy_RDS_username\n",
    "from config import sandy_RDS_password\n",
    "from config import sandy_RDS_endpoint\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "rds_connection_string = f'{sandy_RDS_username}:{sandy_RDS_password}@{sandy_RDS_endpoint}:5432/predict_salary_db'\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')\n",
    "\n",
    "\n",
    "# check that connection worked\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds dataframe to RDS\n",
    "merged_df.to_sql(name='salary_data1', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to confirm that data was loaded successfully\n",
    "pd.read_sql_query('select * from salary_data1', con=engine).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
